{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ8+cDtLlBk9uhGc6hdS8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praffuln/agentic-ai/blob/master/gw_agentic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgQezdm4JEh",
        "outputId": "6b0ec9f0-fddb-4514-8180-98ed1c9820a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "# prompt: print hello world\n",
        "\n",
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai tiktoken chromadb langgraph langchain langchain_community langchainhub ipykernel langchain_groq sentence_transformers boto3 langchain_aws docx exceptions langchain_openai\n",
        "!pip install --upgrade python-docx"
      ],
      "metadata": {
        "id": "wVOW-bao4dak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dependencies"
      ],
      "metadata": {
        "id": "RmPwyiHl5IaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Any, Optional, TypedDict, Dict\n",
        "from pydantic import BaseModel, Field, root_validator\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "import boto3\n",
        "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from docx import Document\n",
        "import json\n",
        "\n",
        "import re\n",
        "from typing import Dict, List"
      ],
      "metadata": {
        "id": "ol834Nm35H49"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "nppj_URn8sep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import BedrockChat\n",
        "from langchain_community.embeddings import BedrockEmbeddings\n",
        "import boto3\n",
        "import os\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"611dff392d7a4f3780f84060b3d6bc9e\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"611dff392d7a4f3780f84060b3d6bc9e\"\n",
        "\n",
        "\n",
        "model_embedding=\"amazon.titan-embed-text-v1\"\n",
        "# bedrock_runtime = boto3.client('bedrock-runtime', region_name=\"us-east-1\")\n",
        "# embedding_model = BedrockEmbeddings(client=bedrock_runtime,model_id=model_embedding)\n",
        "\n",
        "\n",
        "max_tokens = 1024*2*2\n",
        "temperature = 0\n",
        "top_k = 250\n",
        "top_p = 1\n",
        "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
        "version = \"bedrock-2023-05-31\"\n",
        "pause_time = 30\n",
        "\n",
        "\n",
        "\n",
        "from enum import Enum, auto\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class LLM(ABC):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def operation(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class BedrockChatSonnet(LLM):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.model = \"model\"\n",
        "\n",
        "    def operation(self):\n",
        "        #self.model.invoke() ##Like this.\n",
        "        print('invoke to BedrockChatSonnet model !!!!!')\n",
        "\n",
        "\n",
        "class BedrockChatHaiku(LLM):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.model = \"model2\"\n",
        "\n",
        "    def operation(self):\n",
        "        #self.model.invoke() ##Like this.\n",
        "        print('invoke to BedrockChatHaiku model !!!!!')\n",
        "\n",
        "class LLMType(Enum):\n",
        "\n",
        "    BedrockChatSonnet = auto()\n",
        "    BedrockChatHaiku = auto()\n",
        "\n",
        "    def some_method(self):\n",
        "        return f\"Method implemented for {self.name}\"\n",
        "\n",
        "\n",
        "# Creating a dictionary with enum members as keys\n",
        "llm_objects_map = {\n",
        "    LLMType.BedrockChatSonnet: BedrockChatSonnet(),\n",
        "    LLMType.BedrockChatHaiku: BedrockChatHaiku()\n",
        "\n",
        "}\n",
        "\n",
        "class LllProvider:\n",
        "\n",
        "    @staticmethod\n",
        "    def provide(llm_type: LLMType) -> LLM:\n",
        "        return llm_objects_map[llm_type]\n",
        "\n",
        "\n",
        "class LLMInteractor(ABC):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def interact(self, conversation_id, query):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def interact(self, query):\n",
        "        pass\n",
        "\n",
        "class LLMInteractorImpl(LLMInteractor):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.prompManager = object\n",
        "        self.conversation_memory = object\n",
        "        self.llm_provider = LllProvider\n",
        "\n",
        "    def interact(self, conversation_id, query) -> str:\n",
        "        ## based on promptManager, conversation_memory and llm_provider get result from llm\n",
        "        return f\"LLM Result for conversation_id - {conversation_id} and query - {query}\"\n",
        "\n",
        "\n",
        "    def interact(self, query) -> str:\n",
        "        ## based on promptManager, conversation_memory and llm_provider get result from llm\n",
        "        return f\"LLM Result for query - {query}\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   LllProvider.provide(LLMType.BedrockChatSonnet).operation()"
      ],
      "metadata": {
        "id": "0fLPBm0H8vQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Manager"
      ],
      "metadata": {
        "id": "nw45sdqqJYyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from typing import Callable\n",
        "\n",
        "def method1():\n",
        "    return \"method1 result\"\n",
        "\n",
        "def method2():\n",
        "    return 42\n",
        "\n",
        "def method3():\n",
        "    print('Hello World')\n",
        "\n",
        "class Tool(Enum):\n",
        "    METHOD1 = (\"method1\", method1)\n",
        "    METHOD2 = (\"method2\", method2)\n",
        "    METHOD3 = (\"method3\", method3)\n",
        "\n",
        "    def __init__(self, identifier: str, toolFunction: Callable[[], object]):\n",
        "        self.identifier = identifier\n",
        "        self.toolFunction = toolFunction\n",
        "\n",
        "# Accessing METHOD1 and METHOD2 and calling their functions\n",
        "tool1 = Tool.METHOD1\n",
        "tool2 = Tool.METHOD2\n",
        "tool3 = Tool.METHOD3\n",
        "\n",
        "# print(f\"Tool: {tool1.identifier}, Result: {tool1.toolFunction()}\")\n",
        "# print(f\"Tool: {tool2.identifier}, Result: {tool2.toolFunction()}\")\n",
        "# print(f\"Tool: {tool3.identifier}, Result: {tool3.toolFunction()}\")\n",
        "\n",
        "\n",
        "#### Iterate over all the values of tools\n",
        "for tool in Tool:\n",
        "    print(f\"Tool: {tool.identifier}, Result: {tool.toolFunction()}\")\n",
        "\n",
        "####### create ToolList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hzobP_8Jfx8",
        "outputId": "6bb81c2c-e80a-4f95-b165-a59d555356a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool: method1, Result: method1 result\n",
            "Tool: method2, Result: 42\n",
            "Hello World\n",
            "Tool: method3, Result: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edge"
      ],
      "metadata": {
        "id": "kj68MP8MKz7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeType(Enum):\n",
        "    DIRECTED = \"Directed\"\n",
        "    UNDIRECTED = \"Undirected\"\n",
        "\n",
        "\n",
        "class Edge(Enum):\n",
        "\n",
        "    EDGE_1 = (Tool.METHOD1, Tool.METHOD2, EdgeType.DIRECTED)\n",
        "    EDGE_2 = (Tool.METHOD2, Tool.METHOD3, EdgeType.DIRECTED)\n",
        "\n",
        "    def __init__(self, tool1: Tool, tool2: Tool, edge_type: EdgeType):\n",
        "        self.tool1 = tool1\n",
        "        self.tool2 = tool2\n",
        "        self.edge_type = edge_type\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Edge({self.tool1.identifier}, {self.tool2.identifier}, {self.edge_type.value})\"\n",
        "\n",
        "\n",
        "#### Iterate over all the values of edges\n",
        "for edge in Edge:\n",
        "  print(edge)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRKlOoZoK2gE",
        "outputId": "324171d1-b9d3-4a17-877b-546ea6d6b3c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge(method1, method2, Directed)\n",
            "Edge(method2, method3, Directed)\n"
          ]
        }
      ]
    }
  ]
}