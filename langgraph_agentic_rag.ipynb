{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDJ8hJN0cCre+6Xd1ni5QK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praffuln/agentic-ai/blob/master/langgraph_agentic_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi8aB8amSB87",
        "outputId": "75775e20-f0dd-4234-9bcf-84243c1cf39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "# prompt: print hello world\n",
        "\n",
        "print(\"hello world\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai tiktoken chromadb langgraph langchain langchain_community langchainhub ipykernel langchain_groq sentence_transformers\n"
      ],
      "metadata": {
        "id": "XUPvgZUquE8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Literal, Sequence, TypedDict\n",
        "from langchain import hub\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "lKjLajjk3T_W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Keys For GOOGLE_API_KEY\n"
      ],
      "metadata": {
        "id": "YPFF-ppevar4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assigning value to variable\n",
        "GEMINI_API_KEY=''\n",
        "SERPER_API_KEY = ''\n",
        "GROQ_API_KEY = ''\n"
      ],
      "metadata": {
        "id": "LbM3-zGMvdqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup environments\n"
      ],
      "metadata": {
        "id": "n0zcWVGYvr1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SERPER_API_KEY'] = SERPER_API_KEY\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LgoK_XsEvygs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup LLM"
      ],
      "metadata": {
        "id": "hDjCG2BM4415"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Process, Crew, LLM"
      ],
      "metadata": {
        "id": "UcdB75hy47Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Explain how AI works\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "zfuv4uE3Dj2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(\n",
        "    model=\"gemini/gemini-1.5-flash\",\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "SE_J3PLz5cA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from sentence_transformers import SentenceTransformer # Import SentenceTransformer instead of GroqEmbedding\n",
        "\n",
        "\n",
        "llm = ChatGroq(model=\"mixtral-8x7b-32768\")\n",
        "\n",
        "llm.invoke(\"tell me something about ai\")\n",
        "\n",
        "# Now use SentenceTransformer for embedding\n",
        "embedding_model = SentenceTransformer('all-mpnet-base-v2')  # Choose a suitable pre-trained model\n",
        "embedding = embedding_model.encode(\"tell me something about ai\")\n",
        "\n",
        "print(embedding) # Print the embedding to see the result"
      ],
      "metadata": {
        "id": "6DmQlQ0FViCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "fYT_mkVMKDrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls= [\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "      \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"]\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "\n",
        "docs[0][0].metadata"
      ],
      "metadata": {
        "id": "f6S3v7jPKF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap=5)\n",
        "doc_splits=text_splitter.split_documents(docs_list)\n",
        "doc_splits"
      ],
      "metadata": {
        "id": "L0nILKQtMm7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "vectorstore=Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chrome\",\n",
        "    embedding=embedding_model\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCTnL03wOGVQ",
        "outputId": "1dd214e2-55f6-4d7d-819f-351df12b4717"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-84e30c1413db>:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "QWWBnrbyPpaB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuctions & Graph"
      ],
      "metadata": {
        "id": "ZkOKdhL4ANmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ai_assistant(state):\n",
        "  pass\n",
        "    # print(\"---CALL AGENT---\")\n",
        "    # messages = state['messages']\n",
        "    # print(f\"this is my message: {messages}\")\n",
        "\n",
        "    # if len(messages)>1:\n",
        "    #     response=llm.invoke(messages[-1].content)\n",
        "    #     return {\"messages\": [response]}\n",
        "    # else:\n",
        "    #     llm_with_tool = llm.bind_tools(tools)\n",
        "    #     response = llm_with_tool.invoke(messages)\n",
        "    #     #response=handle_query(messages)\n",
        "    #     return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "5RUsp2p0ARbr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state):\n",
        "  pass"
      ],
      "metadata": {
        "id": "0peOMOp2AVUG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite(state):\n",
        "  pass"
      ],
      "metadata": {
        "id": "sLYBYeFNAg8K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "  pass"
      ],
      "metadata": {
        "id": "WywPV4WiAktk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(BaseModel):\n",
        "    pass"
      ],
      "metadata": {
        "id": "D40luyjDA4yP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow=StateGraph(AgentState)\n",
        "workflow.add_node(\"My_AI_Assistant\",ai_assistant)\n",
        "workflow.add_node(\"Vector_Retriever\", retrieve)\n",
        "workflow.add_node(\"Query_Rewriter\", rewrite)\n",
        "workflow.add_node(\"Output_Generator\", generate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "josu2KMNAsq6",
        "outputId": "8d32523d-695f-438d-9e7f-8a0aa1449a38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e28be4d7950>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_edge(START, \"My_AI_Assistant\")\n",
        "workflow.add_edge(\"My_AI_Assistant\", \"Vector_Retriever\")\n",
        "# workflow.add_conditional_edges()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z-oLiDQBetq",
        "outputId": "765bb1a9-9987-4274-8f3f-558a40bd3bfd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e28be4d7950>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "BMKy1NHDEVBu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke({\"messages\": [HumanMessage(content=\"tell me something about ai\")]})"
      ],
      "metadata": {
        "id": "GktjJiiJEc8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}